---
title: "Untitled"
format: html
---

# Build table

## Load data
```{python}
import polars as pl
import pandas as pd
import numpy as np
from great_tables import GT, md, html
dist_mat_pl = pl.read_csv("distance_matrix.csv")
dist_mat_pd = pd.read_csv("distance_matrix.csv")
```

## Prep


```{python}
# columns that will be numeric in table
num_cols = ['ACB','ASW', 'ESN', 'GWD', 'LWK', 'MSL', 'YRI',
 'CLM', 'MXL', 'PEL', 'PUR', 'CDX', 'CHB', 'CHS', 'JPT', 'KHV',
 'CEU','FIN','GBR','IBS','TSI', 'BEB', 'GIH', 'ITU',
 'PJL', 'STU']

# super population groups
## for creating spanners in table
africa_AFR = ['ACB','ASW','ESN','GWD','LWK','MSL','YRI']
americas_AMR = ['CLM','MXL','PEL','PUR']
east_asia_EAS = ['CDX','CHB','CHS','JPT','KHV']
europe_EUR = ['CEU','FIN','GBR','IBS','TSI']
southasia_SAS = ['BEB','GIH','ITU','PJL','STU']

# full populatin details - for notes columns
pop_details = ['African Caribbean in Barbados',
 'African Ancestry in SW USA',
 'Esan in Nigeria',
 'Gambian in Western Division – Mandinka',
 'Luhya in Webuye, Kenya',
 'Mende in Sierra Leone',
 'Yoruba in Ibadan, Nigeria',
 'Colombian in Medellín, Colombia',
 'Mexican Ancestry in L.A. CA, USA',
 'Peruvian in Lima Peru',
 'Puerto Rican in Puerto Rico',
 'Chinese Dai in Xishuangbanna, China', #Chin
 'Han Chinese in Beijing, China',
 'Han Chinese - Southern, China',
 'Japanese in Tokyo, Japan',
 'Kinh in Ho Chi Minh City, Vietnam',
 'Utah Residents (CEPH) with Northern and Western European ancestry',
 'Finnish in Finland',
 'British from England and Scotland',
 'Iberian Populations in Spain',
 'Toscani in Italia',
 'Bengali in Bangladesh',
 'Gujarati Indians in Houston, Texas, USA',
 'Indian Telugu in the U.K.',
 'Punjabi in Lahore, Pakistan [PJL]',
 'Sri Lankan Tamil in the UK']


ethnic_group = ['Afro-Caribbean',
 'African American',
 'Esan',
 'Mandinka',
 'Luhya',
 'Mende',
 'Yoruba',
 'Colombian',
 'Mexican-American',
 'Peruvian',
 'Puerto Rican',
 'Dai', #Chin
 'Han',
 'Han',
 'Japanese',
 'Kinh', # in Ho Chi Minh City, Vietnam
 'European American',
 'Finnish',
 'British / Scottish',
 'Spainish-Iberian',
 'Toscan-Italy',
 'Bengali',
 'Gujarati', # Indians in Houston, Texas, USA
 'Telugu', # in the U.K.
 'Punjabi', # in Lahore, Pakistan [PJL]
 'Tamil'] #Sri Lankan Tamil in the UK

# country where sample was taken
## For country column
country_sampling = ['Barbados',
 'USA', # African Union? Pan-Africa
 'Nigeria', #Nigeria
 'Gambia',
 'Kenya',
 'Sierra Leone',
 'Nigeria', #Nigeria
 'Colombia',
 'Mexico',
 'Peru',
 'Puerto Rico',
 'China',# Chinese Dai in Xishuangbanna
 'China',# Han Chinese in Beijing
 'China',#Han Chinese - Southern, China
 'Japan',
 'Vietnam',
 'USA', #European Union
 'Finland',
 'UK',
 'Spain',
 'Italy',
 'Bangladesh',
 'India',#india Gujarat
 'India',#India Telugu
 'India',#India  Punjab
 'Sri Lanka']


icon = ['barbados.png',
 'pan_africa_flag.png', # African Union? Pan-Africa
 'nigeria.png', #Nigeria
 'gambia.png',
 'kenya.png',
 'sierra_leone.png',
 'nigeria.png', #Nigeria
 'colombia.png',
 'mexico.png',
 'peru.png',
 'puerto_rico.png',
 'china.png',# Chinese Dai in Xishuangbanna
 'china.png',# Han Chinese in Beijing
 'china.png',#Han Chinese - Southern, China
 'japan.png',
 'vietnam.png',
 'USA.png', #European Union
 'finland.png',
 'UK.png',
 'spain.png',
 'italy.png',
 'bangladesh.png',
 'india.png',#india Gujarat
 'india.png',#India Telugu
 'india.png',#India  Punjab
 'sri_lanka.png']
```



```{python}
# isolate distance matrix
columns =  dist_mat_pd.columns
columns = columns.drop(["sup_pop","pop"])
columns
```

```{python}
# set diagonal to be to None
## NOte - elements on the diagonal and not == 0
### numeric issues?
## ACHTUNG - throws warning about slices blah blah blah
## check on on3 column
dist_mat_pd.ACB[dist_mat_pd.ACB < 0.01] = None

# Set full diagonal to be none
## ACHTUNG - throws warning about slices blah blah blah
for column in columns:
    dist_mat_pd[column][dist_mat_pd[column] < 0.01] = None
```

```{python}
# find min/max for scaling
global_min = dist_mat_pd[columns].min().min()
global_max = dist_mat_pd[columns].max().max()
dist_mat_pd[columns] = dist_mat_pd[columns]/global_max*100
```

```{python}
# create column for condensing super population designations
# this is a workaround b/c I'm havin issues with row stubs
sup_pop_orig = ["AFR","AFR","AFR","AFR","AFR","AFR","AFR",
"AMR","AMR","AMR","AMR",
"EAS","EAS","EAS","EAS","EAS",
"EUR","EUR","EUR","EUR","EUR",
"SAS","SAS","SAS","SAS","SAS"]

sup_pop_alt = ["","","","AFR","","","",
"","","AMR","",
"","","EAS","","",
"","","EUR","","",
"","","SAS","",""]
```

```{python}
dist_mat_pd.sup_pop = sup_pop_alt
```

pop_details
country

```{python}
dist_mat_pd["country"] = country_sampling
dist_mat_pd["pop_details"] = pop_details
dist_mat_pd["ethnic_cultural_group"] = ethnic_group
dist_mat_pd["country_sampling"] = country_sampling
dist_mat_pd["icon"] = icon



```


```{python}
dist_mat_pd.head()
```

```{python}
# Save final table
import pandas as pd
dist_mat_pd.to_csv("dist_mat_final.csv",    index= None)
```

```{python}
import pandas as pd
import polars as pl
dist_mat_pd = pd.read_csv("dist_mat_final.csv")
dist_mat_pl = pl.read_csv("dist_mat_final.csv")
```


```{python}
dist_mat_pd.head()
```

```{python}
GT(dist_mat_pd)
```



```{python}
dist_mat_pd.head()
```

```{python}
filler_row = pd.DataFrame(np.repeat(None,dist_mat_pd.shape[1])).T
filler_row.columns = dist_mat_pd.columns
```

```{python}
dist_mat_pd2 = pd.concat([dist_mat_pd.iloc[:7], 
              filler_row, 
              dist_mat_pd.iloc[7:11],
              filler_row, 
              dist_mat_pd.iloc[11:15],
              filler_row, 
              dist_mat_pd.iloc[16:20],
              filler_row, 
              dist_mat_pd.iloc[21:]
              ]).reset_index(drop=True)
```

```{python}
dist_mat_pd2.head()
```


```{python}
#temp = dist_mat_pd[["sup_pop","pop","ethnic_cultural_group","country_sampling","icon"]]
#(
#    GT(temp)
#    .fmt_image("icon", path="icons/")
#)
```
```{python}
from great_tables import GT, md, html
# make my table
(
    GT(dist_mat_pd2)
    .tab_header(title="Euclidean distance between 1000 Genomes populations",
     subtitle="Subtitle goes here"
     )
    #.tab_style(
    #    style=style.text(size = "0"),
    #    locations=loc.body(columns=num_cols),
    #)
    .cols_hide(columns=["country","pop_details"])
    .fmt_image("icon", path="icons/")
    #.tab_stub(
    #  rowname_col="row", 
    #  groupname_col="sup_pop"
    #)
    .tab_spanner(
        label="Group",
        columns=["sup_pop", "pop","icon"]
    )
    .tab_spanner(
        label="Africa",
        columns=africa_AFR
    )
    .tab_spanner(
        label="Americas",
        columns=americas_AMR
    )
    .tab_spanner(
        label="East Asia",
        columns=east_asia_EAS
    )
    .tab_spanner(
        label="Western Europe",
        columns=europe_EUR
    )
    .tab_spanner(
        label="South Asia",
        columns=southasia_SAS
    )
    .tab_spanner(
        label="Genetic Distances",
        columns=num_cols
    )
    .tab_spanner(
        label="Notes",
        columns=["ethnic_cultural_group","country_sampling"]
    )
    .cols_label(
        sup_pop = "Super population",
        pop = "Population",
        country_sampling = "Sampling location",
        ethnic_cultural_group = "Ethnic / Cultural Group",
        icon = "Geographic origin"
    )
    .cols_align(align="center")
    .fmt_number(columns=num_cols, decimals=0, use_seps=False)
    #.sub_zero(zero_text='nil')
    .data_color(
        domain=[90, 0],
        palette=["white", "orange"],
        na_color="white",
    )
    .tab_source_note(source_note="Add citation")
    .cols_move_to_start(columns=["sup_pop", "pop", "icon"])

)
```




```{python}
!quarto publish quarto-pub
```